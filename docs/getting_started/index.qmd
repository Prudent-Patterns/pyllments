---
title: "Getting Started Tutorial"
lightbox: true
---
Lets create a simple flow that helps illustrate the core concepts of pyllments by building and serving a chat application. 

Please make sure that you've [installed pyllments](/installation.qmd) if you want to follow along.

If you don't care about building flows, you can hop on over to the [recipes section](/recipes) to run pre-built applications. Or [skip to the very end](#putting-it-all-together) to run our example flow.

## 1. Creating your first `Element` 

:::{.column-margin}
![Element Diagram](getting_started_element.jpg)
:::

The fundamental building block of pyllments, is as you may have guessed, an `Element`. 


An element is composed of a `Model` that handles the business logic, `Ports` that handle the communication between elements, and optionally, `Views` that handles the frontend representation of the element.

```python
from pyllments.elements import ChatInterfaceElement # <1> 

chat_interface_el = ChatInterfaceElement() # <2>
```
1. Import the `ChatInterfaceElement` from the `pyllments.elements` subpackage. This is how to import an element efficiently.
2. Create an instance of the `ChatInterfaceElement`.

## 2. Adding more elements
Now that we're getting the hang of it, lets create a couple more.

```python
from pyllments.elements import LLMChatElement, HistoryHandlerElement

llm_chat_el = LLMChatElement(model_name='gpt-4o') # <1>
history_handler_el = HistoryHandlerElement( # <2>
    history_token_limit=1000, 
    tokenizer_model='gpt-4o' # <2>
)

```
1. Create an instance of the `LLMChatElement` with the model name set to 'gpt-4o'. LLMChatElement uses the [LiteLLM naming system](https://models.litellm.ai) and is compatible with the chat models supported by LiteLLM. All you need is the corresponding API key in an .env file.
2. Create an instance of the `HistoryHandlerElement` with the token limit set to 1000 tokens as measured by the gpt-4o tokenizer. This is the default tokenizer used and can be expected to be a good enough estimate for most use cases.

## 3. Your first flow

Lets take a moment to think about what we want to achieve. We are creating a chat interface which uses an LLM to respond to message while also taking into account the history of the conversation.

Below, you can see that each individual element has its own unique set of input and output ports as well as a designated Payload type it either emits or receives. In this case, we're only using the `MessagePayload` and `List[MessagePayload]` types. For an output port to connect to an input port, its payload type must be compatible with the input port's payload type. 

For the `HistoryHandlerElement` to connect to the `LLMChatElement`, the `messages_emit_input` port of the `LLMChatElement` must be able to accept a `List[MessagePayload]` type.

![Flow Diagram](getting_started_flow.jpg){.column-page}

To facilitate the proper communication between the elements:

1. When we type a message into the `ChatInterfaceElement` and hit send, it emits a `MessagePayload` through the `message_output` port.
2. That message is recieved by the `HistoryHandlerElement` through the `message_emit_input` port.
3. The `_emit_input` suffix specifies that upon recieving a payload, `HistoryHandlerElement` will emit a payload. The list of `MessagePayload`s that is emitted from the `messages_output` port consists of the message history stored internally with the latest `MessagePayload` appended at the end of that list.
4. When the `LLMChatElement` recieves a `List[MessagePayload]` through the `messages_emit_input` port, it sends the list of messages to the LLM we previously specified and returns a `MessagePayload` through the `message_output` port.
5. The first input port that the `MessagePayload` is received by is the `messages_input` port of the `HistoryHandlerElement`, which unlike the `message_emit_input` port, does not emit any payload, it instead only appends the `MessagePayload` to the internal message history.
6. The second input that the `MessagePayload` is received by is the `message_input` port of the `ChatInterfaceElement`, which causes the message to be streamed to the chatfeed we will soon see. 

## 4. Connecting the elements

Now that we have a flow in mind, connecting the elements is a breeze.

```python
chat_interface_el.ports.message_output > history_handler_el.ports.message_emit_input

history_handler_el.ports.messages_output > llm_chat_el.ports.messages_emit_input

llm_chat_el.ports.message_output > history_handler_el.ports.messages_input

llm_chat_el.ports.message_output > chat_interface_el.ports.message_input
```

The ports are accessed using dot notation on the `ports` attribute of the element.
In the case of `llm_chat_el.ports.message_output > chat_interface_el.ports.message_input`, we are connecting an output port of the `LLMChatElement` to an input port of the `ChatInterfaceElement` using the `>` operator, with the output port being on the left side of it. It is equivalent to `llm_chat_el.ports.message_output.connect(chat_interface_el.ports.message_input)`.


## 5. Creating the views
After connecting the elements, we can create the views responsible for generating the visual components of our application.

![Element Views](getting_started_views.jpg) 

```python
import panel as pn # <1>

interface_view = chat_interface_el.create_interface_view(width=600, height=800) # <2>
chat_history_view = history_handler_el.create_context_view(width=220) # <3>
model_selector_view = llm_chat_el.create_model_selector_view() # <4>

main_view = pn.Column( # <5>
    model_selector_view,
    pn.Spacer(height=10),
    pn.Row(
        interface_view,
        pn.Spacer(width=10),
        chat_history_view
        ),
    styles={'width': 'fit-content'}
) # <5>
```

1. The panel library is imported to help with the view layout. The front end of pyllments is built using [panel](https://panel.holoviz.org), and supports rendering panel widgets and panes within pyllments applications.
2. `interface_view` is created by calling the `create_interface_view` method of the `ChatInterfaceElement`. This view is a wrapper around the `chat_input_view`, `chat_feed_view`, and `send_button_view`. The height and width are specified in pixels.
3. `chat_history_view` is created by calling the `create_context_view` method of the `HistoryHandlerElement`. This view contains the current chat history which is sent to the LLM. Here, only the width is specified, as the height will stretch to fit its container.
4. `model_selector_view` is created by calling the `create_model_selector_view` method of the `LLMChatElement`. This view allows us to select the model we wish to chat with. The width isn't specified because we want it to stretch to fit its container.
5. Lastly, we use the panel row and column layout helpers to organize the views. The spacers are used to create some visual space between the views and neaten things up.

## 6. Serve your flow as an application

To create an application from your flow, you must create a function decorated with a `@flow` decorator that returns a view object. Every time the page is reloaded, the code in that function will be executed. This means that you have the option of instantiating the elements every single time the page is reloaded, or reusing them.

::: {.panel-tabset}
## Reused Elements
```python
from pyllments import flow

# {{ Element creation here }}

@flow
def my_flow():
    # {{ View creation here }}
    return main_view
```

## New Element Creation

```python
from pyllments import flow

@flow
def my_flow():
    # {{ Element and view creation here }}
    return main_view
```

:::

Make sure that you .env file is in your working directory or its parent directories. (Alternatively, you can specify the path to the .env file using the `--env` flag)

Save your code as a python file `my_flow.py` and serve it:

```bash
pyllments serve my_flow.py
```
Add a `--logging` flag to see under the hood.

::: {.callout-tip collapse="true"}
## More info on the pyllments serve command

```bash
pyllments serve --help
-----------------------------------------
 Usage: pyllments serve [OPTIONS] FILENAME                                               
                                                                                         
 Start a Pyllments server                                                                
                                                                                         
╭─ Arguments ───────────────────────────────────────────────────────────────────────────╮
│ *    filename      TEXT  [default: None] [required]                                   │
╰───────────────────────────────────────────────────────────────────────────────────────╯
╭─ Options ─────────────────────────────────────────────────────────────────────────────╮
│ --logging            --no-logging             Enable logging. [default: no-logging]   │
│ --logging-level                      TEXT     Set logging level. [default: INFO]      │
│ --no-gui             --no-no-gui              Don't look for GUI components.          │
│                                               [default: no-no-gui]                    │
│ --port                               INTEGER  Port to run server on. [default: 8000]  │
│ --env                                TEXT     Path to .env file. [default: None]      │
│ --host           -H                  TEXT     Network interface to bind the server    │
│                                               to. Defaults to localhost (127.0.0.1)   │
│                                               for safer local development.            │
│                                               [default: 127.0.0.1]                    │
│ --profile            --no-profile             Enable profiling output.                │
│                                               [default: no-profile]                   │
│ --config         -c                  TEXT     Additional configuration options for    │
│                                               the served file. Provide either         │
│                                               multiple key=value pairs or a single    │
│                                               dictionary literal (e.g. '{"key":       │
│                                               "value"}').                             │
│ --help                                        Show this message and exit.             │
╰───────────────────────────────────────────────────────────────────────────────────────╯
```
:::

![Front End Video](getting_started_gui.mp4){.nolightbox}

## 7. Putting it all together

```python
import panel as pn
from pyllments import flow
from pyllments.elements import (
    ChatInterfaceElement, 
    LLMChatElement, 
    HistoryHandlerElement
)


chat_interface_el = ChatInterfaceElement()
llm_chat_el = LLMChatElement(model_name='gpt-4o')
history_handler_el = HistoryHandlerElement(
    history_token_limit=1000, 
    tokenizer_model='gpt-4o'
)

chat_interface_el.ports.message_output > history_handler_el.ports.message_emit_input
history_handler_el.ports.messages_output > llm_chat_el.ports.messages_emit_input
llm_chat_el.ports.message_output > history_handler_el.ports.messages_input
llm_chat_el.ports.message_output > chat_interface_el.ports.message_input

interface_view = chat_interface_el.create_interface_view(width=600, height=800)
chat_history_view = history_handler_el.create_context_view(width=220)
model_selector_view = llm_chat_el.create_model_selector_view()

@flow
def my_flow():
    main_view = pn.Column(
        model_selector_view,
        pn.Spacer(height=10),
        pn.Row(
            interface_view,
            pn.Spacer(width=10),
            chat_history_view
            ),
        styles={'width': 'fit-content'}
    )
    return main_view
```

**CLI:**
```bash
pyllments serve my_flow.py --logging
```
